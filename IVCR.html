<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval</title>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css" media="screen"/>
</head>
<body>
    <div class="container">
        <h1 class="project-title">IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval</h1>
        <div class="icon-container">
            <ul class="icon-list">
                <li class="icon-item">
                    <a href="https://arxiv.org/abs/2309.13925">
                        <img src="img/file-pdf.png" alt="Paper">
                        <h4><strong>Paper</strong></h4>
                    </a>
                </li>
                <li class="icon-item">
                    <a href="https://github.com/Xuange923/Surveillance-Video-Understanding">
                        <img src="img/github.png" alt="Code">
                        <h4><strong>Code and Dataset</strong></h4>
                    </a>
                </li>
            </ul>
        </div>

        <h2>Abstract</h2>
    <P>In recent years, significant developments have been made in both video retrieval
and video moment retrieval tasks, which respectively retrieve complete videos
or moments for a given text query. These advancements have greatly improved
user satisfaction during the search process. However, previous work has failed to
establish meaningful “interaction” between the retrieval system and the user, and
its one-way retrieval paradigm can no longer fully meet the personalization and
dynamics of user needs.
In this paper, we propose a more realistic setting, Interactive Video Corpus Re-
trieval task (IVCR) that enables multi-turn, conversational, realistic interactions
between the user and the retrieval system. To facilitate research on this challenging
task, we introduce IVCR-200K, a bilingual, multi-turn, conversational, abstract se-
mantic high-quality dataset that supports video retrieval and even moment retrieval.
Furthermore, we propose a comprehensive framework based on multi-modal large
language models (MLLMs) to support users’ several interaction modes with more
explainable solutions. Our extensive experiments demonstrate the effectiveness of
our dataset and framework. The dataset and code are available at xxx.</P>
		<hr>
	    <h2>Datasets</h2>
	    <p>To implement an interactive video retrieval system, we constructed a multi-turn, conversational
dataset comprising 193,434 interactions sourced from 5 video repositories. This dataset encompasses
functionalities such as video retrieval, video moment retrieval, and natural dialogue.</p>
	    <div class="image-container">
		   <img src="gif/1.gif" style="width: 300px; height: auto; position: absolute; right: 0px; bottom: 0px;">

</div>
	        <hr>
	<h2>Visualization Quality</h2>
	      <img src="a.png" alt="GIF Image" loop>
	     <hr>
	<h2>Framwork</h2>
	    <img src="img/tone.png" alt="Paper">
	        <hr>
</body>
</html>
